{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting AI_worker_client.py\n"
     ]
    }
   ],
   "source": [
    "%%file AI_worker_client.py\n",
    "#\n",
    "# Copyright 2017-2018, the original author or authors.\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# You may not use this file except in compliance\n",
    "# with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing,\n",
    "# software distributed under the License is distributed on an\n",
    "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
    "# KIND, either express or implied. See the License for the\n",
    "# specific language governing permissions and limitations\n",
    "# under the License.\n",
    "#\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import common_client\n",
    "\n",
    "from commons.src.logging.setup_logging import setup_logging\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "from commons.src.load_balancer.worker_load_balancer import WorkerLoadBalancer\n",
    "from commons.src.load_balancer.worker_load_balancer import WorkerInfo\n",
    "from commons.src.config import config_loader\n",
    "from commons.src.load_balancer.worker_info import WorkerInfo\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "class AIflyError(Exception):\n",
    "    pass\n",
    "\n",
    "class prediction_output:\n",
    "    \"\"\"\n",
    "    Contains input details and model_id and data\n",
    "    \"\"\"\n",
    "    def __init__(self, result, status):\n",
    "        self.result = result\n",
    "        self.status = status\n",
    "        \n",
    "\n",
    "class AIWorkerClient:\n",
    "    def __init__(self, load_balancer):\n",
    "        setup_logging()\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.load_balancer = load_balancer\n",
    "        self.logger.info(\"load balancer inited...\")\n",
    "        self.worker_connections = {}\n",
    "        self.logger.info(\"AIWorkerClient Inited...\")\n",
    "        # self.load_balancer = WorkerLoadBalancer(model_to_worker_config_path)\n",
    "        self.worker_to_AI_client_map = {}\n",
    "\n",
    "        worker_id_to_worker_map = self.load_balancer.get_all_workers(\"AI\")\n",
    "\n",
    "        # Build model to AI client map\n",
    "        #worker_id_to_worker_map:\"{u'localhost-9091-1': <commons.src.load_balancer.worker_info.WorkerInfo instance at 0x1106af908>, u'localhost-9092-2': }\"\n",
    "        if worker_id_to_worker_map:\n",
    "            for worker_id, worker in worker_id_to_worker_map.iteritems():   \n",
    "                self.worker_to_AI_client_map[worker_id] = self.make_clients(worker)\n",
    "\n",
    "    def make_clients(self, worker):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            host:\n",
    "            port:\n",
    "\n",
    "        Returns: http client for the worker at the given host and port\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            dd = common_client.DD(host=worker.host,port=worker.port)\n",
    "            data={'n':2}\n",
    "            dd.set_return_format(dd.RETURN_PYTHON)\n",
    "            #inf = dd.predict(data)\n",
    "            #print(inf)\n",
    "            #aiurl='http://%s:%d' % (worker.host,worker.port)\n",
    "            #client = common_client.Client(aiurl)\n",
    "            return dd\n",
    "        except ConnectionError:\n",
    "            raise AIflyError('Unable to connect to the server, please try again later.')\n",
    "\n",
    "    def predict(self, prediction_input):\n",
    "        \"\"\"\n",
    "        AI prediction\n",
    "        Args:\n",
    "            prediction_input: PredictionInput\n",
    "        Returns: PredictionOutput\n",
    "        \"\"\"\n",
    "        self.logger.info(\"AI predict has been called..\")\n",
    "        print 'prediction_input.model_id',prediction_input.model_id\n",
    "        worker = self.load_balancer.choose_worker(\"AI\", prediction_input.model_id)\n",
    "\n",
    "        self.logger.debug('Chosen worker_id: %s for predict ', str(worker.global_worker_id))\n",
    "\n",
    "        if worker.global_worker_id in self.worker_to_AI_client_map:\n",
    "            client= self.worker_to_AI_client_map[worker.global_worker_id]\n",
    "        else:\n",
    "            client = self.make_clients(worker)\n",
    "            self.worker_to_AI_client_map[worker.global_worker_id] = client\n",
    "\n",
    "        po = None\n",
    "        retry_count = 3\n",
    "        trial_number = 0\n",
    "        while trial_number < retry_count:\n",
    "            trial_number += 1\n",
    "            try:\n",
    "                #predict=prediction_input.model_id\n",
    "                \n",
    "                prediction_output.status = 'Success'\n",
    "                prediction_output.result = client.predict(prediction_input.data)\n",
    "            except Exception as e:\n",
    "                prediction_output.result = 'None'\n",
    "                prediction_output.status = 'Failure'\n",
    "                self.logger.error('Predict has failed.. ', exc_info=True)\n",
    "            else:\n",
    "                break\n",
    "            finally:\n",
    "                self.logger.error('Predict has failed.. ', exc_info=True)\n",
    "\n",
    "        return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # self.load_balancer = WorkerLoadBalancer(model_to_worker_config_path)\n",
    "        self.worker_to_caffe_thrift_client_map = {}\n",
    "\n",
    "        worker_id_to_worker_map = self.load_balancer.get_all_workers('Caffe')\n",
    "\n",
    "        # Build model to thrift client map\n",
    "        if worker_id_to_worker_map:\n",
    "            for worker_id, worker in worker_id_to_worker_map.iteritems():\n",
    "                self.worker_to_caffe_thrift_client_map[worker_id] = get_thrift_client(worker)\n",
    "\n",
    "    def predict(self, prediction_input):\n",
    "        \"\"\"\n",
    "        Caffe prediction\n",
    "        Args:\n",
    "            prediction_input: PredictionInput\n",
    "        Returns: PredictionOutput\n",
    "        \"\"\"\n",
    "        self.logger.info(\"Caffe predict has been called..\")\n",
    "        worker = self.load_balancer.choose_worker('Caffe', prediction_input.model_id)\n",
    "\n",
    "        self.logger.debug('Chosen worker_id: %s for predict ', str(worker.global_worker_id))\n",
    "\n",
    "        if worker.global_worker_id in self.worker_to_caffe_thrift_client_map:\n",
    "            client, trans = self.worker_to_caffe_thrift_client_map[worker.global_worker_id]\n",
    "        else:\n",
    "            client, trans = get_thrift_client(worker)\n",
    "            self.worker_to_caffe_thrift_client_map[worker.global_worker_id] = client, trans\n",
    "\n",
    "        po = None\n",
    "        retry_count = 3\n",
    "        trial_number = 0\n",
    "        while trial_number < retry_count:\n",
    "            trial_number += 1\n",
    "            try:\n",
    "                trans.open()\n",
    "                po = client.predict(prediction_input)\n",
    "            except Exception as e:\n",
    "                po = PredictionOutput()\n",
    "                po.bo.status = 'Failure'\n",
    "                self.logger.error('Predict has failed.. ', exc_info=True)\n",
    "            else:\n",
    "                break\n",
    "            finally:\n",
    "                if trans.isOpen():\n",
    "                    trans.close()\n",
    "\n",
    "        return po"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
